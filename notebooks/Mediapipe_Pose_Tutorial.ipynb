{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dafbe84",
   "metadata": {},
   "source": [
    "# MediaPipe Holistic Keypoint Extraction\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a streamlined tool for extracting human pose keypoints from videos using **Google's MediaPipe Holistic** library. The extracted data is saved as CSV files for further analysis in multimodal interaction research.\n",
    "\n",
    "### What This Notebook Does\n",
    "\n",
    "1. **Extracts MediaPipe Holistic landmarks** from video files:\n",
    "   - 33 body landmarks (with X, Y, Z coordinates + visibility scores)\n",
    "   - 42 hand landmarks (21 per hand, with X, Y, Z coordinates)\n",
    "   - 478 face landmarks (with X, Y, Z coordinates)\n",
    "\n",
    "2. **Exports time series data** as CSV files:\n",
    "   - `*_body.csv` - Body keypoints\n",
    "   - `*_hands.csv` - Hand keypoints  \n",
    "   - `*_face.csv` - Face keypoints\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- Batch processing of multiple videos\n",
    "- Automatic handling of missing landmarks (filled with NaN values)\n",
    "- Frame-by-frame time series output with millisecond timestamps\n",
    "- Simple folder-based workflow (input videos ‚Üí output CSV files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f6dbef",
   "metadata": {},
   "source": [
    "## üìë¬†Notebook overview\n",
    "1. **Environment¬†setup** ‚Äî install & import requirements\n",
    "2. **Configuration** ‚Äî set video source and pipeline parameters\n",
    "3. **Pipeline functions** ‚Äî create and run the MediaPipe graph\n",
    "4. **Exercises** ‚Äî analyse tracking quality and landmark trajectories\n",
    "5. **Discussion & extras** ‚Äî reflect on speed/accuracy trade‚Äëoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1898197",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f357b",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è¬†Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb07cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe Holistic Keypoint Extraction\n",
      "==================================================\n",
      "Input folder: /Users/ferdinandpaar/Library/Mobile Documents/com~apple~CloudDocs/Projects/MPI_Max_Planck_Institut/MPI_Github/MPI_website_github/MediaPipe_keypoints_extraction/input_videos\n",
      "Output folder: /Users/ferdinandpaar/Library/Mobile Documents/com~apple~CloudDocs/Projects/MPI_Max_Planck_Institut/MPI_Github/MPI_website_github/MediaPipe_keypoints_extraction/Mediapipe_results\n",
      "\n",
      "Videos to process: 1\n",
      "  1. salma_hayek_short.mp4\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Configure folder paths\n",
    "input_folder = \"../input_videos/\"\n",
    "output_folder = \"../Mediapipe_results/\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List all video files in input folder\n",
    "video_files = [f for f in listdir(input_folder) if isfile(join(input_folder, f)) and not f.startswith('.')]\n",
    "\n",
    "# Display configuration\n",
    "print(\"MediaPipe Holistic Keypoint Extraction\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Input folder: {os.path.abspath(input_folder)}\")\n",
    "print(f\"Output folder: {os.path.abspath(output_folder)}\")\n",
    "print(f\"\\nVideos to process: {len(video_files)}\")\n",
    "for i, vf in enumerate(video_files, 1):\n",
    "    print(f\"  {i}. {vf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42639839",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce50963b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body landmarks: 33\n",
      "Hand landmarks: 42\n",
      "Face landmarks: 478\n",
      "\n",
      "Total CSV columns:\n",
      "  Body CSV: 133 columns\n",
      "  Hands CSV: 127 columns\n",
      "  Face CSV: 1435 columns\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe modules\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Define landmark names for body (33 landmarks)\n",
    "markers_body = [\n",
    "    'NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "    'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', \n",
    "    'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX',\n",
    "    'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "    'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX'\n",
    "]\n",
    "\n",
    "# Define landmark names for hands (42 landmarks - 21 per hand)\n",
    "markers_hands = [\n",
    "    'LEFT_WRIST', 'LEFT_THUMB_CMC', 'LEFT_THUMB_MCP', 'LEFT_THUMB_IP', 'LEFT_THUMB_TIP', 'LEFT_INDEX_FINGER_MCP',\n",
    "    'LEFT_INDEX_FINGER_PIP', 'LEFT_INDEX_FINGER_DIP', 'LEFT_INDEX_FINGER_TIP', 'LEFT_MIDDLE_FINGER_MCP', \n",
    "    'LEFT_MIDDLE_FINGER_PIP', 'LEFT_MIDDLE_FINGER_DIP', 'LEFT_MIDDLE_FINGER_TIP', 'LEFT_RING_FINGER_MCP', \n",
    "    'LEFT_RING_FINGER_PIP', 'LEFT_RING_FINGER_DIP', 'LEFT_RING_FINGER_TIP', 'LEFT_PINKY_FINGER_MCP', \n",
    "    'LEFT_PINKY_FINGER_PIP', 'LEFT_PINKY_FINGER_DIP', 'LEFT_PINKY_FINGER_TIP',\n",
    "    'RIGHT_WRIST', 'RIGHT_THUMB_CMC', 'RIGHT_THUMB_MCP', 'RIGHT_THUMB_IP', 'RIGHT_THUMB_TIP', 'RIGHT_INDEX_FINGER_MCP',\n",
    "    'RIGHT_INDEX_FINGER_PIP', 'RIGHT_INDEX_FINGER_DIP', 'RIGHT_INDEX_FINGER_TIP', 'RIGHT_MIDDLE_FINGER_MCP', \n",
    "    'RIGHT_MIDDLE_FINGER_PIP', 'RIGHT_MIDDLE_FINGER_DIP', 'RIGHT_MIDDLE_FINGER_TIP', 'RIGHT_RING_FINGER_MCP', \n",
    "    'RIGHT_RING_FINGER_PIP', 'RIGHT_RING_FINGER_DIP', 'RIGHT_RING_FINGER_TIP', 'RIGHT_PINKY_FINGER_MCP', \n",
    "    'RIGHT_PINKY_FINGER_PIP', 'RIGHT_PINKY_FINGER_DIP', 'RIGHT_PINKY_FINGER_TIP'\n",
    "]\n",
    "\n",
    "# Define landmark names for face (478 landmarks)\n",
    "markers_face = [str(x) for x in range(478)]\n",
    "\n",
    "# Create column headers for CSV files\n",
    "# Body: time, X_LANDMARK, Y_LANDMARK, Z_LANDMARK, visibility_LANDMARK\n",
    "columns_body = ['time']\n",
    "for mark in markers_body:\n",
    "    for pos in ['X', 'Y', 'Z', 'visibility']:\n",
    "        columns_body.append(f\"{pos}_{mark}\")\n",
    "\n",
    "# Hands: time, X_LANDMARK, Y_LANDMARK, Z_LANDMARK\n",
    "columns_hands = ['time']\n",
    "for mark in markers_hands:\n",
    "    for pos in ['X', 'Y', 'Z']:\n",
    "        columns_hands.append(f\"{pos}_{mark}\")\n",
    "\n",
    "# Face: time, X_LANDMARK, Y_LANDMARK, Z_LANDMARK\n",
    "columns_face = ['time']\n",
    "for mark in markers_face:\n",
    "    for pos in ['X', 'Y', 'Z']:\n",
    "        columns_face.append(f\"{pos}_{mark}\")\n",
    "\n",
    "# Helper functions\n",
    "def num_there(s):\n",
    "    \"\"\"Check if there are numbers in a string\"\"\"\n",
    "    return any(i.isdigit() for i in s)\n",
    "\n",
    "def convert_landmarks_to_str(landmarks_obj):\n",
    "    \"\"\"Convert MediaPipe landmark object to string list\"\"\"\n",
    "    landmarks_str = str(landmarks_obj).strip(\"[]\")\n",
    "    landmarks_str = landmarks_str.split(\"\\n\")\n",
    "    return landmarks_str[:-1]  # Ignore last empty element\n",
    "\n",
    "def extract_positions(landmarks):\n",
    "    \"\"\"Extract numerical position values from landmark strings\"\"\"\n",
    "    landmarks_str = convert_landmarks_to_str(landmarks)\n",
    "    positions = []\n",
    "    for value in landmarks_str:\n",
    "        if num_there(value):\n",
    "            stripped = value.split(':', 1)[1].strip()\n",
    "            positions.append(stripped)\n",
    "    return positions\n",
    "\n",
    "print(f\"Body landmarks: {len(markers_body)}\")\n",
    "print(f\"Hand landmarks: {len(markers_hands)}\")\n",
    "print(f\"Face landmarks: {len(markers_face)}\")\n",
    "print(f\"\\nTotal CSV columns:\")\n",
    "print(f\"  Body CSV: {len(columns_body)} columns\")\n",
    "print(f\"  Hands CSV: {len(columns_hands)} columns\")\n",
    "print(f\"  Face CSV: {len(columns_face)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d61abb",
   "metadata": {},
   "source": [
    "## 2. Process Videos and Extract Keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b39124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing video 1/1: salma_hayek_short.mp4\n",
      "============================================================\n",
      "Video properties:\n",
      "  Resolution: 1920x1080\n",
      "  FPS: 29.97002997002997\n",
      "  Total frames: 1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761036019.467228 12537653 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M1 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1761036019.564038 12540535 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761036019.581286 12540535 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761036019.585263 12540536 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761036019.585266 12540540 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761036019.585326 12540534 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761036019.596558 12540534 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761036019.596843 12540540 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761036019.597610 12540536 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1761036019.603664 12540531 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 1110/1136 frames (97.7%)\n",
      "  Completed processing 1110 frames\n",
      "  Saved: salma_hayek_short_body.csv\n",
      "  Saved: salma_hayek_short_hands.csv\n",
      "  Saved: salma_hayek_short_face.csv\n",
      "\n",
      "============================================================\n",
      "Processing complete!\n",
      "All CSV files saved to: /Users/ferdinandpaar/Library/Mobile Documents/com~apple~CloudDocs/Projects/MPI_Max_Planck_Institut/MPI_Github/MPI_website_github/MediaPipe_keypoints_extraction/Mediapipe_results\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Process each video\n",
    "for video_idx, video_file in enumerate(video_files, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing video {video_idx}/{len(video_files)}: {video_file}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Open video\n",
    "    video_path = os.path.join(input_folder, video_file)\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video properties:\")\n",
    "    print(f\"  Resolution: {frame_width}x{frame_height}\")\n",
    "    print(f\"  FPS: {fps}\")\n",
    "    print(f\"  Total frames: {total_frames}\")\n",
    "    \n",
    "    # Initialize time series data storage\n",
    "    time = 0\n",
    "    ts_body = [columns_body]\n",
    "    ts_hands = [columns_hands]\n",
    "    ts_face = [columns_face]\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    # Process video with MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,\n",
    "        enable_segmentation=False,\n",
    "        refine_face_landmarks=True\n",
    "    ) as holistic:\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = capture.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Display progress every 30 frames\n",
    "            if frame_count % 30 == 0:\n",
    "                progress = (frame_count / total_frames) * 100\n",
    "                print(f\"  Progress: {frame_count}/{total_frames} frames ({progress:.1f}%)\", end='\\r')\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Process with MediaPipe\n",
    "            results = holistic.process(image_rgb)\n",
    "            \n",
    "            # Extract landmarks or fill with NaN if not detected\n",
    "            if results.pose_landmarks is not None:\n",
    "                # Extract body landmarks\n",
    "                sample_body = extract_positions(results.pose_landmarks)\n",
    "                sample_body.insert(0, time)\n",
    "                \n",
    "                # Extract hand landmarks with NaN for missing hands\n",
    "                sample_left_hand = extract_positions(results.left_hand_landmarks)\n",
    "                sample_right_hand = extract_positions(results.right_hand_landmarks)\n",
    "                \n",
    "                # Fill missing left hand with NaN\n",
    "                if len(sample_left_hand) == 0:\n",
    "                    sample_left_hand = [np.nan for _ in range(63)]  # 21 landmarks * 3 coordinates = 63\n",
    "                \n",
    "                # Fill missing right hand with NaN\n",
    "                if len(sample_right_hand) == 0:\n",
    "                    sample_right_hand = [np.nan for _ in range(63)]  # 21 landmarks * 3 coordinates = 63\n",
    "                \n",
    "                # Combine hands\n",
    "                sample_hands = sample_left_hand + sample_right_hand\n",
    "                sample_hands.insert(0, time)\n",
    "                \n",
    "                # Extract face landmarks\n",
    "                sample_face = extract_positions(results.face_landmarks) if results.face_landmarks else []\n",
    "                if len(sample_face) == 0:\n",
    "                    sample_face = [np.nan for _ in range(1434)]  # 478 landmarks * 3 coordinates = 1434\n",
    "                sample_face.insert(0, time)\n",
    "                \n",
    "            else:\n",
    "                # No landmarks detected - fill with NaN\n",
    "                sample_body = [np.nan for _ in range(len(columns_body) - 1)]\n",
    "                sample_body.insert(0, time)\n",
    "                \n",
    "                sample_hands = [np.nan for _ in range(len(columns_hands) - 1)]\n",
    "                sample_hands.insert(0, time)\n",
    "                \n",
    "                sample_face = [np.nan for _ in range(len(columns_face) - 1)]\n",
    "                sample_face.insert(0, time)\n",
    "            \n",
    "            # Append to time series\n",
    "            ts_body.append(sample_body)\n",
    "            ts_hands.append(sample_hands)\n",
    "            ts_face.append(sample_face)\n",
    "            \n",
    "            # Increment time (in milliseconds)\n",
    "            time += (1000 / fps)\n",
    "    \n",
    "    # Release video capture\n",
    "    capture.release()\n",
    "    \n",
    "    print(f\"\\n  Completed processing {frame_count} frames\")\n",
    "    \n",
    "    # Save CSV files\n",
    "    base_filename = os.path.splitext(video_file)[0]\n",
    "    \n",
    "    # Save body CSV\n",
    "    body_csv_path = os.path.join(output_folder, f\"{base_filename}_body.csv\")\n",
    "    with open(body_csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(ts_body)\n",
    "    print(f\"  Saved: {base_filename}_body.csv\")\n",
    "    \n",
    "    # Save hands CSV\n",
    "    hands_csv_path = os.path.join(output_folder, f\"{base_filename}_hands.csv\")\n",
    "    with open(hands_csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(ts_hands)\n",
    "    print(f\"  Saved: {base_filename}_hands.csv\")\n",
    "    \n",
    "    # Save face CSV\n",
    "    face_csv_path = os.path.join(output_folder, f\"{base_filename}_face.csv\")\n",
    "    with open(face_csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(ts_face)\n",
    "    print(f\"  Saved: {base_filename}_face.csv\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Processing complete!\")\n",
    "print(f\"All CSV files saved to: {os.path.abspath(output_folder)}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907137b",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Your MediaPipe keypoint data has been extracted and saved as CSV files in the `Mediapipe_results/` folder.\n",
    "\n",
    "### Output Files\n",
    "\n",
    "For each video, three CSV files are created:\n",
    "- `<video_name>_body.csv` - 33 body landmarks with X, Y, Z, visibility\n",
    "- `<video_name>_hands.csv` - 42 hand landmarks with X, Y, Z\n",
    "- `<video_name>_face.csv` - 478 face landmarks with X, Y, Z\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "These CSV files can be used for:\n",
    "- Smoothing and normalization (see `Smoothing/` folder)\n",
    "- Kinematic analysis - speed, acceleration, jerk (see `Speed_Acceleration_Jerk/` folder)\n",
    "- Gesture segmentation (see `Submovements_Holds/` folder)\n",
    "- Multimodal merging with ELAN annotations (see `Merging_Motion_ELAN/` folder)\n",
    "- And more!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa1250",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPI_ferpaa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
